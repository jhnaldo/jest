\section{Related Work}\label{sec:related}

Our technique is related to three research fields: differential testing,
fuzzing, and fault localization.

\textbf{Differential Testing:} Differential testing\cite{diff-test} utilizes
multiple implementations as cross-referencing oracles to find semantics bugs.
Researchers applied this technique for various applications, such as Java
Virtual Machine (JVM) implementations\cite{diff-jvm}, SSL/TLS certification
validation logic\cite{nezha,diff-ssl,diff-ssl2}, web
applications\cite{diff-web}, and binary lifters\cite{ir-diff-test}.  Moreover,
\textsc{Nezha}\cite{nezha} introduces a guided differential testing tool with
the concept of $\delta$-diversity to efficiently find semantic bugs.  However,
they have fundamental limitations because they use only the cross-referencing
oracles and target potential bugs in implementations.  Our $N$+1-version differential
testing extends the idea of differential testing with not only $N$ different
implementations but also a mechanized specification to test both of them.
Moreover, our approach automatically generates conformance tests directly from
the specification.

\textbf{Fuzzing:} Fuzzing is a software testing technique for detecting
security vulnerabilities by generating\cite{imf,gen-fuzzing,csmith} or
mutating\cite{mutate-fuzzing,mutate-fuzzing2,mutate-fuzzing3} test inputs.  For
JavaScript\cite{js-hopl} engines, Patrice et al.\cite{grammar-whitebox}
presented white-box fuzzing using JavaScript grammar, Han et
al.\cite{codealchemist} presented CodeAlchemist that generates JavaScript code
snippets based on semantics-aware assembly, Wang et al.\cite{superion}
presented Superion using Grammar-aware greybox fuzzing, Park et al.\cite{die}
presented \textsc{Die} using an aspect-preserving mutation, and Lee et
al.\cite{montage} presented Montage using neural network language models
(NNLMs).  However, they only focus on finding security vulnerabilities but not
the semantics correctness. Unlike fuzzing approaches, our $N$+1-version differential
testing focuses on semantics bugs by comparing multiple implementations with
the mechanized specification.  To extract mechanized specification from
ECMAScript, we utilized a tool $\jiset$, which is a JavaScript IR-based
semantics extraction toolchain.  Moreover, it could localize not only
specification bugs in ECMAScript but also bugs in JavaScript engines indirectly
using the bug locations in ECMAScript.

\textbf{Fault Localization:} To localize detected bugs in ECMAScript, we used
Spectrum Based Fault Localization (SBFL)\cite{sbfl-survey}, which is a ranking
technique based on likelihood of being faulty for each program element.
Tarantula\cite{tarantula, tarantula2} was the first tool that supports SBFL
with a simple formula and many formulas have been developed\cite{ample, zoltar,
sbfl-model, effect-sbfl} to increase the accuracy of bug localization.
Moreover, Sohn et al.\cite{fluccs} introduced a novel approach for fault
localization technique using code and change metrics via learning of SBFL
formulas.  While we utilize the basic formula introduced by Tarantula, we
believe that it is possible to improve the accuracy of bug localization by
using more advanced SBFL techniques.

% SAGE\cite{sage}
